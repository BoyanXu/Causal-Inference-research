{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "## sklearn\n",
    "import sklearn.svm as svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "\n",
    "## Scipy\n",
    "from scipy.sparse import csr_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "top_grams = pd.DataFrame()\n",
    "metric = pd.DataFrame(index=[\"Precision\",\"Recall\",\"Accuracy\", \"F1\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data_folder = '../Data/reddit/title/'\n",
    "positive_file_names = ['depression', 'SuicideWatch', 'anxiety', 'ask_reddit', 'psychosis', 'stress']\n",
    "negative_file_names = ['ask_reddit']\n",
    "file_extension = '.txt'\n",
    "\n",
    "# Load positive dataframe\n",
    "pos_df = pd.read_csv(filepath_or_buffer=data_folder + positive_file_names[0] + file_extension, sep='❖', quotechar='⩐', header =None, names =['text'], error_bad_lines=False)\n",
    "pos_df['source'] = positive_file_names[0]\n",
    "pos_df['label'] = 1\n",
    "\n",
    "neg_df = pd.read_csv(filepath_or_buffer=data_folder + negative_file_names[0] + file_extension, sep='❖', quotechar='⩐', header =None, names =['text'], error_bad_lines=False)\n",
    "## Balance the positive and negative samples\n",
    "neg_df = neg_df.sample(n=pos_df.shape[0], random_state=1)\n",
    "neg_df['source'] = negative_file_names[0]\n",
    "neg_df['label'] = 0\n",
    "\n",
    "df = pd.concat([pos_df, neg_df], ignore_index=True)\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/boyanxu/anaconda3/envs/causal_inference/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the separator encoded in utf-8 is > 1 char long, and the 'c' engine does not support such separators; you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "/Users/boyanxu/anaconda3/envs/causal_inference/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just my thoughts</td>\n",
       "      <td>depression</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why am I not happy although i’m getting some g...</td>\n",
       "      <td>depression</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’m not ungrateful, but i’m not happy</td>\n",
       "      <td>depression</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sad music that will make you love yourself</td>\n",
       "      <td>depression</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Everything I try to do I lose interest in imme...</td>\n",
       "      <td>depression</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956313</th>\n",
       "      <td>Would you rather be stranded out in space or s...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956314</th>\n",
       "      <td>What did you see on the internet recently that...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956315</th>\n",
       "      <td>If you were to die right now, what would be yo...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956316</th>\n",
       "      <td>You can push two buttons. The first one will m...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956317</th>\n",
       "      <td>If countries/regions were leveling zones in an...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>956318 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text      source  label\n",
       "0                                        Just my thoughts  depression      1\n",
       "1       Why am I not happy although i’m getting some g...  depression      1\n",
       "2                   I’m not ungrateful, but i’m not happy  depression      1\n",
       "3              Sad music that will make you love yourself  depression      1\n",
       "4       Everything I try to do I lose interest in imme...  depression      1\n",
       "...                                                   ...         ...    ...\n",
       "956313  Would you rather be stranded out in space or s...  ask_reddit      0\n",
       "956314  What did you see on the internet recently that...  ask_reddit      0\n",
       "956315  If you were to die right now, what would be yo...  ask_reddit      0\n",
       "956316  You can push two buttons. The first one will m...  ask_reddit      0\n",
       "956317  If countries/regions were leveling zones in an...  ask_reddit      0\n",
       "\n",
       "[956318 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Text preprocessing\n",
    "- Tokenizes\n",
    "- Make text lowercase\n",
    "- Removes hyperlinks\n",
    "- Remove punctuation\n",
    "- Removes numbers\n",
    "- Removes useless words \"stopwords\"\n",
    "- Stemming/Lemmatization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stemmer    = nltk.SnowballStemmer(\"english\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "        Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "        and remove words containing numbers.\n",
    "    '''\n",
    "    text = (unicodedata.normalize('NFKD', text)\n",
    "    .encode('ascii', 'ignore')\n",
    "    .decode('utf-8', 'ignore')\n",
    "    .lower())\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) # remove urls\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # remove punctuation\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_data(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    stemmer    = nltk.SnowballStemmer(\"english\")\n",
    "    text = clean_text(text)                                                     # Clean puntuation, urls, and so on\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)    # Remove stopwords\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split())                # Stemm all the words in the sentence\n",
    "    return text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "df['clean_text'] = df.text.astype(str).apply(preprocess_data)\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just my thoughts</td>\n",
       "      <td>depression</td>\n",
       "      <td>1</td>\n",
       "      <td>thought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why am I not happy although i’m getting some g...</td>\n",
       "      <td>depression</td>\n",
       "      <td>1</td>\n",
       "      <td>happi although im get good news nnmi brain ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’m not ungrateful, but i’m not happy</td>\n",
       "      <td>depression</td>\n",
       "      <td>1</td>\n",
       "      <td>im ungrat im happi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sad music that will make you love yourself</td>\n",
       "      <td>depression</td>\n",
       "      <td>1</td>\n",
       "      <td>sad music make love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Everything I try to do I lose interest in imme...</td>\n",
       "      <td>depression</td>\n",
       "      <td>1</td>\n",
       "      <td>everyth tri lose interest immedi passion energ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956313</th>\n",
       "      <td>Would you rather be stranded out in space or s...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>would rather strand space strand deep depth ocean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956314</th>\n",
       "      <td>What did you see on the internet recently that...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>see internet recent made smile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956315</th>\n",
       "      <td>If you were to die right now, what would be yo...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>die right would last wish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956316</th>\n",
       "      <td>You can push two buttons. The first one will m...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>push two button first one make everyon believ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956317</th>\n",
       "      <td>If countries/regions were leveling zones in an...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>countriesregion level zone rpg level would</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>956318 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text      source  label  \\\n",
       "0                                        Just my thoughts  depression      1   \n",
       "1       Why am I not happy although i’m getting some g...  depression      1   \n",
       "2                   I’m not ungrateful, but i’m not happy  depression      1   \n",
       "3              Sad music that will make you love yourself  depression      1   \n",
       "4       Everything I try to do I lose interest in imme...  depression      1   \n",
       "...                                                   ...         ...    ...   \n",
       "956313  Would you rather be stranded out in space or s...  ask_reddit      0   \n",
       "956314  What did you see on the internet recently that...  ask_reddit      0   \n",
       "956315  If you were to die right now, what would be yo...  ask_reddit      0   \n",
       "956316  You can push two buttons. The first one will m...  ask_reddit      0   \n",
       "956317  If countries/regions were leveling zones in an...  ask_reddit      0   \n",
       "\n",
       "                                               clean_text  \n",
       "0                                                 thought  \n",
       "1       happi although im get good news nnmi brain ful...  \n",
       "2                                      im ungrat im happi  \n",
       "3                                     sad music make love  \n",
       "4       everyth tri lose interest immedi passion energ...  \n",
       "...                                                   ...  \n",
       "956313  would rather strand space strand deep depth ocean  \n",
       "956314                     see internet recent made smile  \n",
       "956315                          die right would last wish  \n",
       "956316  push two button first one make everyon believ ...  \n",
       "956317         countriesregion level zone rpg level would  \n",
       "\n",
       "[956318 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Top n-gram features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df['split'] = np.random.choice([\"train\", \"val\", \"test\"], size=df.shape[0], p=[.7, .15, .15])\n",
    "x_train = df[df[\"split\"] == \"train\"]\n",
    "y_train = x_train[\"label\"]\n",
    "x_val = df[df[\"split\"] == \"val\"]\n",
    "y_val = x_val[\"label\"]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "## Training pipeline\n",
    "tf_idf = Pipeline([\n",
    "     ('tfidf', TfidfVectorizer(ngram_range=(1,3))),\n",
    "     (\"classifier\", svm.LinearSVC(C=1.0, class_weight=\"balanced\"))\n",
    " ])\n",
    "\n",
    "tf_idf.fit(x_train[\"clean_text\"], y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                ('classifier', LinearSVC(class_weight='balanced'))])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "## Confidence measure\n",
    "f1_score(y_val, tf_idf.predict(x_val[\"clean_text\"]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9228514878988854"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "coefs = tf_idf.named_steps[\"classifier\"].coef_\n",
    "if type(coefs) == csr_matrix:\n",
    "    coefs.toarray().tolist()[0]\n",
    "else:\n",
    "    coefs.tolist()\n",
    "    \n",
    "feature_names = tf_idf.named_steps[\"tfidf\"].get_feature_names()\n",
    "coefs_and_features = list(zip(coefs[0], feature_names))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "top_grams = pd.DataFrame()\n",
    "top_grams[\"anxity\"] = sorted(coefs_and_features, key=lambda x: x[0], reverse=True)[:20]\n",
    "for x in top_grams[\"anxity\"]:\n",
    "    print(x[0], '\\t',x[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7.361898069467513 \t im\n",
      "6.992189685751805 \t depress\n",
      "6.970554594977517 \t nni\n",
      "6.551149157993388 \t ive\n",
      "4.967404285735691 \t antidepress\n",
      "4.3769586603159105 \t ni\n",
      "4.310062279064543 \t cant\n",
      "3.973800273169233 \t med\n",
      "3.971081797385684 \t suicid\n",
      "3.9580380571956173 \t therapist\n",
      "3.8149908331642397 \t dont\n",
      "3.7674543040642976 \t vent\n",
      "3.7617511504073415 \t guess\n",
      "3.745890237811832 \t therapi\n",
      "3.613743650685313 \t wellbutrin\n",
      "3.468218900891058 \t mayb\n",
      "3.3954130842431933 \t numb\n",
      "3.3556458220573484 \t id\n",
      "3.3256383637940656 \t ill\n",
      "3.305248631879399 \t zoloft\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "features = [x[1] for x in sorted(coefs_and_features, key=lambda x: x[0], reverse=True)[:5000]]\n",
    "vectorizer = CountVectorizer(vocabulary=features)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "tmp = df.loc[:10]\n",
    "X = vectorizer.fit_transform(tmp.clean_text)\n",
    "print(X.toarray()) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [2 0 0 ... 0 0 0]\n",
      " ...\n",
      " [3 2 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# %%timeit\n",
    "# ## Build features for clean_text\n",
    "# features = [x[1] for x in sorted(coefs_and_features, key=lambda x: x[0], reverse=True)[:100]]\n",
    "# for feature in features:\n",
    "#     df[feature] = df.clean_text.str.contains(feature).map(int)\n",
    "# df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "## Build train & test set \n",
    "X = df.clean_text\n",
    "Y = df.label\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X, Y, random_state=20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "## 5-fold cross validation\n",
    "features = [x[1] for x in sorted(coefs_and_features, key=lambda x: x[0], reverse=True)[:5000]]\n",
    "clf = Pipeline([\n",
    "    ('countvectorizer', CountVectorizer(vocabulary=features)),\n",
    "    ('classifier', svm.LinearSVC(C=1.0, class_weight=\"balanced\"))\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "\n",
    "cv_metrics = cross_validate(clf, X, Y, cv=5, scoring=['precision', 'recall', 'accuracy', 'f1'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/boyanxu/anaconda3/envs/causal_inference/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/boyanxu/anaconda3/envs/causal_inference/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/boyanxu/anaconda3/envs/causal_inference/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/boyanxu/anaconda3/envs/causal_inference/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/boyanxu/anaconda3/envs/causal_inference/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "\n",
    "metric[positive_file_names[0] + \"_CV\"] = [cv_metrics['test_precision'].mean(),\n",
    "                                            cv_metrics['test_recall'].mean(),\n",
    "                                            cv_metrics['test_accuracy'].mean(),\n",
    "                                            cv_metrics['test_f1'].mean()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "clf.fit(X_train, Y_train)\n",
    "print(\"SVM claasifier F1 score: {0}\".format(f1_score(Y_test, clf.predict(X_test))))\n",
    "\n",
    "test_metrics = [precision_score(Y_test, clf.predict(X_test)),\n",
    "                recall_score(Y_test, clf.predict(X_test)),\n",
    "                accuracy_score(Y_test, clf.predict(X_test)),\n",
    "                f1_score(Y_test, clf.predict(X_test))]\n",
    "metric[positive_file_names[0] + \"_test\"] = test_metrics"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/boyanxu/anaconda3/envs/causal_inference/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVM claasifier F1 score: 0.8105141777462871\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "## Save the model\n",
    "with open(positive_file_names[0] + '.sav', 'wb') as sav:\n",
    "    pickle.dump(clf, sav)\n",
    "# loaded_model = pickle.load(open(positive_file_names[0] + '.sav', 'rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "metric"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depression_CV</th>\n",
       "      <th>depression_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.909011</td>\n",
       "      <td>0.911097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.728049</td>\n",
       "      <td>0.729931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.827587</td>\n",
       "      <td>0.828856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.808514</td>\n",
       "      <td>0.810514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           depression_CV  depression_test\n",
       "Precision       0.909011         0.911097\n",
       "Recall          0.728049         0.729931\n",
       "Accuracy        0.827587         0.828856\n",
       "F1              0.808514         0.810514"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2bc74cc49154a9ee15c00e6801fd896878f8e345944270608f40bd45df5df7c1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('causal_inference': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}