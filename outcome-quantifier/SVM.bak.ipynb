{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sklearn\n",
    "import sklearn.svm as svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "## Scipy\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_grams = pd.DataFrame()\n",
    "metric = pd.DataFrame(index=[\"Precision\",\"Recall\",\"Accuracy\", \"F1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boyanxu/anaconda3/envs/causal_inference/lib/python3.9/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the separator encoded in utf-8 is > 1 char long, and the 'c' engine does not support such separators; you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n",
      "/Users/boyanxu/anaconda3/envs/causal_inference/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I get rid of bad thoughts thoughts of w...</td>\n",
       "      <td>stress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worry</td>\n",
       "      <td>stress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Idk how I can describe it aside from it being ...</td>\n",
       "      <td>stress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I interviewed for a position that would change...</td>\n",
       "      <td>stress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New product that can help anxiety/stress? Prod...</td>\n",
       "      <td>stress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>Can a European get an American credit card?</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>What are some conclusions humans made about an...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>[SERIOUS] What’s the most disturbing thing you...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>[serious] when do you brush your teeth?</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>People who leave their curtains open and light...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text      source  label\n",
       "0     How do I get rid of bad thoughts thoughts of w...      stress      1\n",
       "1                                                 Worry      stress      1\n",
       "2     Idk how I can describe it aside from it being ...      stress      1\n",
       "3     I interviewed for a position that would change...      stress      1\n",
       "4     New product that can help anxiety/stress? Prod...      stress      1\n",
       "...                                                 ...         ...    ...\n",
       "8511        Can a European get an American credit card?  ask_reddit      0\n",
       "8512  What are some conclusions humans made about an...  ask_reddit      0\n",
       "8513  [SERIOUS] What’s the most disturbing thing you...  ask_reddit      0\n",
       "8514            [serious] when do you brush your teeth?  ask_reddit      0\n",
       "8515  People who leave their curtains open and light...  ask_reddit      0\n",
       "\n",
       "[8516 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = '../Data/reddit/title/'\n",
    "positive_file_names = ['stress', 'psychosis', 'anxiety', 'depression', 'SuicideWatch']\n",
    "negative_file_names = ['ask_reddit']\n",
    "file_extension = '.txt'\n",
    "\n",
    "# Load positive dataframe\n",
    "pos_df = pd.read_csv(filepath_or_buffer=data_folder + positive_file_names[0] + file_extension, sep='❖', quotechar='⩐', header =None, names =['text'], error_bad_lines=False)\n",
    "pos_df['source'] = positive_file_names[0]\n",
    "pos_df['label'] = 1\n",
    "\n",
    "neg_df = pd.read_csv(filepath_or_buffer=data_folder + negative_file_names[0] + file_extension, sep='❖', quotechar='⩐', header =None, names =['text'], error_bad_lines=False)\n",
    "## Balance the positive and negative samples\n",
    "neg_df = neg_df.sample(n=pos_df.shape[0], random_state=1)\n",
    "neg_df['source'] = negative_file_names[0]\n",
    "neg_df['label'] = 0\n",
    "\n",
    "df = pd.concat([pos_df, neg_df], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing\n",
    "- Tokenizes\n",
    "- Make text lowercase\n",
    "- Removes hyperlinks\n",
    "- Remove punctuation\n",
    "- Removes numbers\n",
    "- Removes useless words \"stopwords\"\n",
    "- Stemming/Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stemmer    = nltk.SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "        Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "        and remove words containing numbers.\n",
    "    '''\n",
    "    text = (unicodedata.normalize('NFKD', text)\n",
    "    .encode('ascii', 'ignore')\n",
    "    .decode('utf-8', 'ignore')\n",
    "    .lower())\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) # remove urls\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # remove punctuation\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_data(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    stemmer    = nltk.SnowballStemmer(\"english\")\n",
    "    text = clean_text(text)                                                     # Clean puntuation, urls, and so on\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)    # Remove stopwords\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split())                # Stemm all the words in the sentence\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I get rid of bad thoughts thoughts of w...</td>\n",
       "      <td>stress</td>\n",
       "      <td>1</td>\n",
       "      <td>get rid bad thought thought worri peopl think ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worry</td>\n",
       "      <td>stress</td>\n",
       "      <td>1</td>\n",
       "      <td>worri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Idk how I can describe it aside from it being ...</td>\n",
       "      <td>stress</td>\n",
       "      <td>1</td>\n",
       "      <td>idk describ asid inform feel like got courtesi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I interviewed for a position that would change...</td>\n",
       "      <td>stress</td>\n",
       "      <td>1</td>\n",
       "      <td>interview posit would chang life feel mani dif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New product that can help anxiety/stress? Prod...</td>\n",
       "      <td>stress</td>\n",
       "      <td>1</td>\n",
       "      <td>new product help anxietystress product concept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>Can a European get an American credit card?</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>european get american credit card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8512</th>\n",
       "      <td>What are some conclusions humans made about an...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>conclus human made anim certain anim got compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>[SERIOUS] What’s the most disturbing thing you...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>what disturb thing youv wit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>[serious] when do you brush your teeth?</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>brush teeth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>People who leave their curtains open and light...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>peopl leav curtain open light night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8516 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text      source  label  \\\n",
       "0     How do I get rid of bad thoughts thoughts of w...      stress      1   \n",
       "1                                                 Worry      stress      1   \n",
       "2     Idk how I can describe it aside from it being ...      stress      1   \n",
       "3     I interviewed for a position that would change...      stress      1   \n",
       "4     New product that can help anxiety/stress? Prod...      stress      1   \n",
       "...                                                 ...         ...    ...   \n",
       "8511        Can a European get an American credit card?  ask_reddit      0   \n",
       "8512  What are some conclusions humans made about an...  ask_reddit      0   \n",
       "8513  [SERIOUS] What’s the most disturbing thing you...  ask_reddit      0   \n",
       "8514            [serious] when do you brush your teeth?  ask_reddit      0   \n",
       "8515  People who leave their curtains open and light...  ask_reddit      0   \n",
       "\n",
       "                                             clean_text  \n",
       "0     get rid bad thought thought worri peopl think ...  \n",
       "1                                                 worri  \n",
       "2     idk describ asid inform feel like got courtesi...  \n",
       "3     interview posit would chang life feel mani dif...  \n",
       "4     new product help anxietystress product concept...  \n",
       "...                                                 ...  \n",
       "8511                  european get american credit card  \n",
       "8512  conclus human made anim certain anim got compl...  \n",
       "8513                        what disturb thing youv wit  \n",
       "8514                                        brush teeth  \n",
       "8515                peopl leav curtain open light night  \n",
       "\n",
       "[8516 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'] = df.text.apply(preprocess_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top n-gram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['split'] = np.random.choice([\"train\", \"val\", \"test\"], size=df.shape[0], p=[.7, .15, .15])\n",
    "x_train = df[df[\"split\"] == \"train\"]\n",
    "y_train = x_train[\"label\"]\n",
    "x_val = df[df[\"split\"] == \"val\"]\n",
    "y_val = x_val[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                ('classifier', LinearSVC(class_weight='balanced'))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Training pipeline\n",
    "tf_idf = Pipeline([\n",
    "     ('tfidf', TfidfVectorizer(ngram_range=(1,3))),\n",
    "     (\"classifier\", svm.LinearSVC(C=1.0, class_weight=\"balanced\"))\n",
    " ])\n",
    "\n",
    "tf_idf.fit(x_train[\"clean_text\"], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8833202819107282"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Confidence measure\n",
    "f1_score(y_val, tf_idf.predict(x_val[\"clean_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = tf_idf.named_steps[\"classifier\"].coef_\n",
    "if type(coefs) == csr_matrix:\n",
    "    coefs.toarray().tolist()[0]\n",
    "else:\n",
    "    coefs.tolist()\n",
    "    \n",
    "feature_names = tf_idf.named_steps[\"tfidf\"].get_feature_names()\n",
    "coefs_and_features = list(zip(coefs[0], feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.5900657390351 \t stress\n",
      "3.3798123029621068 \t im\n",
      "2.2354184487075575 \t relax\n",
      "2.1061811495190716 \t help\n",
      "1.9464947869056883 \t anxieti\n",
      "1.9177541433392646 \t calm\n",
      "1.917550329897508 \t cant\n",
      "1.9148900790670367 \t feel\n",
      "1.6916868522532575 \t medit\n",
      "1.615459216302344 \t health\n",
      "1.5456801764434083 \t posit\n",
      "1.5394039226498626 \t burnout\n",
      "1.4808747400986733 \t heart\n",
      "1.44782466362786 \t ive\n",
      "1.4462379558993712 \t mental\n",
      "1.3633081154808464 \t depress\n",
      "1.3466256382239208 \t reddit work\n",
      "1.3420296618715453 \t music\n",
      "1.3295250372359524 \t symptom\n",
      "1.3039327767059508 \t what wrong\n"
     ]
    }
   ],
   "source": [
    "top_grams = pd.DataFrame()\n",
    "top_grams[\"anxity\"] = sorted(coefs_and_features, key=lambda x: x[0], reverse=True)[:20]\n",
    "for x in top_grams[\"anxity\"]:\n",
    "    print(x[0], '\\t',x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# ## Build features for clean_text\n",
    "# features = [x[1] for x in sorted(coefs_and_features, key=lambda x: x[0], reverse=True)[:100]]\n",
    "# for feature in features:\n",
    "#     df[feature] = df.clean_text.str.contains(feature).map(int)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Build features for clean_text\n",
    "feature_arrays = []\n",
    "features = [x[1] for x in sorted(coefs_and_features, key=lambda x: x[0], reverse=True)[:5000]]\n",
    "\n",
    "for feature in features:\n",
    "    feature_arrays.append(df.clean_text.str.contains(feature).map(int).to_numpy(dtype=bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build features for clean_text\n",
    "feature_arrays = []\n",
    "features = [x[1] for x in sorted(coefs_and_features, key=lambda x: x[0], reverse=True)[:5000]]\n",
    "\n",
    "for feature in features:\n",
    "    feature_arrays.append(df.clean_text.str.contains(feature).map(int).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build train & test set \n",
    "# X = df.drop(columns=['text', 'source', 'label', 'clean_text', 'split'])\n",
    "X = pd.DataFrame(np.stack(feature_arrays, axis=1), columns=features)\n",
    "Y = df.label\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X, Y, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5-fold cross validation\n",
    "clf = svm.LinearSVC()\n",
    "\n",
    "cv_metrics = [cross_val_score(clf, X, Y, cv=5, scoring='precision').mean(),\n",
    "              cross_val_score(clf, X, Y, cv=5, scoring='recall').mean(),\n",
    "              cross_val_score(clf, X, Y, cv=5, scoring='accuracy').mean(),\n",
    "              cross_val_score(clf, X, Y, cv=5, scoring='f1').mean()]\n",
    "metric[positive_file_names[0] + \"_CV\"] = cv_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM claasifier F1 score: 0.869750283768445\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train)\n",
    "print(\"SVM claasifier F1 score: {0}\".format(f1_score(Y_test, clf.predict(X_test))))\n",
    "\n",
    "test_metrics = [precision_score(Y_test, clf.predict(X_test)),\n",
    "                recall_score(Y_test, clf.predict(X_test)),\n",
    "                accuracy_score(Y_test, clf.predict(X_test)),\n",
    "                f1_score(Y_test, clf.predict(X_test))]\n",
    "metric[positive_file_names[0] + \"_test\"] = test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the model\n",
    "with open(positive_file_names[0] + '.sav', 'wb') as sav:\n",
    "    pickle.dump(clf, sav)\n",
    "# loaded_model = pickle.load(open(positive_file_names[0] + '.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psychosis_CV</th>\n",
       "      <th>psychosis_test</th>\n",
       "      <th>stress_CV</th>\n",
       "      <th>stress_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.942569</td>\n",
       "      <td>0.940184</td>\n",
       "      <td>0.943771</td>\n",
       "      <td>0.950472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.810164</td>\n",
       "      <td>0.809134</td>\n",
       "      <td>0.761881</td>\n",
       "      <td>0.750466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.880374</td>\n",
       "      <td>0.877059</td>\n",
       "      <td>0.858271</td>\n",
       "      <td>0.854392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.871249</td>\n",
       "      <td>0.869750</td>\n",
       "      <td>0.842403</td>\n",
       "      <td>0.838710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           psychosis_CV  psychosis_test  stress_CV  stress_test\n",
       "Precision      0.942569        0.940184   0.943771     0.950472\n",
       "Recall         0.810164        0.809134   0.761881     0.750466\n",
       "Accuracy       0.880374        0.877059   0.858271     0.854392\n",
       "F1             0.871249        0.869750   0.842403     0.838710"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2bc74cc49154a9ee15c00e6801fd896878f8e345944270608f40bd45df5df7c1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('causal_inference': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
