{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sklearn\n",
    "import sklearn.svm as svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "## Scipy\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_grams = pd.DataFrame()\n",
    "metric = pd.DataFrame(index=[\"Precision\",\"Recall\",\"Accuracy\", \"F1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boyanxu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the separator encoded in utf-8 is > 1 char long, and the 'c' engine does not support such separators; you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n",
      "Skipping line 94941: Expected 1 fields in line 94941, saw 5\n",
      "Skipping line 94942: Expected 1 fields in line 94942, saw 3\n",
      "/Users/boyanxu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: ParserWarning: Falling back to the 'python' engine because the separator encoded in utf-8 is > 1 char long, and the 'c' engine does not support such separators; you can avoid this warning by specifying engine='python'.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paranoia is something I struggle with a lot, p...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is happening to me?</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I believe anxiety started this year and I real...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does one start therapy?</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I heard a a lot of people experience less anxi...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426491</th>\n",
       "      <td>What is your own definition of happiness, or w...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426492</th>\n",
       "      <td>how much do you earn per month? state your age...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426493</th>\n",
       "      <td>I went to a theme park and rode multiple rolle...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426494</th>\n",
       "      <td>People do Reddit, what’s the most questionable...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426495</th>\n",
       "      <td>What movie that made others cry didn’t make yo...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426496 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text      source  label\n",
       "0       Paranoia is something I struggle with a lot, p...     anxiety      1\n",
       "1                                What is happening to me?     anxiety      1\n",
       "2       I believe anxiety started this year and I real...     anxiety      1\n",
       "3                             How does one start therapy?     anxiety      1\n",
       "4       I heard a a lot of people experience less anxi...     anxiety      1\n",
       "...                                                   ...         ...    ...\n",
       "426491  What is your own definition of happiness, or w...  ask_reddit      0\n",
       "426492  how much do you earn per month? state your age...  ask_reddit      0\n",
       "426493  I went to a theme park and rode multiple rolle...  ask_reddit      0\n",
       "426494  People do Reddit, what’s the most questionable...  ask_reddit      0\n",
       "426495  What movie that made others cry didn’t make yo...  ask_reddit      0\n",
       "\n",
       "[426496 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = '../Data/reddit/title/'\n",
    "positive_file_names = ['anxiety', 'ask_reddit', 'depression', 'psychosis', 'stress', 'SuicideWatch']\n",
    "negative_file_names = ['ask_reddit']\n",
    "file_extension = '.txt'\n",
    "\n",
    "# Load positive dataframe\n",
    "pos_df = pd.read_csv(filepath_or_buffer=data_folder + positive_file_names[0] + file_extension, sep='❖', quotechar='⩐', header =None, names =['text'], error_bad_lines=False)\n",
    "pos_df['source'] = positive_file_names[0]\n",
    "pos_df['label'] = 1\n",
    "\n",
    "neg_df = pd.read_csv(filepath_or_buffer=data_folder + negative_file_names[0] + file_extension, sep='❖', quotechar='⩐', header =None, names =['text'], error_bad_lines=False)\n",
    "## Balance the positive and negative samples\n",
    "neg_df = neg_df.sample(n=pos_df.shape[0], random_state=1)\n",
    "neg_df['source'] = negative_file_names[0]\n",
    "neg_df['label'] = 0\n",
    "\n",
    "df = pd.concat([pos_df, neg_df], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing\n",
    "- Tokenizes\n",
    "- Make text lowercase\n",
    "- Removes hyperlinks\n",
    "- Remove punctuation\n",
    "- Removes numbers\n",
    "- Removes useless words \"stopwords\"\n",
    "- Stemming/Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stemmer    = nltk.SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "        Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "        and remove words containing numbers.\n",
    "    '''\n",
    "    text = (unicodedata.normalize('NFKD', text)\n",
    "    .encode('ascii', 'ignore')\n",
    "    .decode('utf-8', 'ignore')\n",
    "    .lower())\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) # remove urls\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # remove punctuation\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_data(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    stemmer    = nltk.SnowballStemmer(\"english\")\n",
    "    text = clean_text(text)                                                     # Clean puntuation, urls, and so on\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)    # Remove stopwords\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split())                # Stemm all the words in the sentence\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paranoia is something I struggle with a lot, p...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>1</td>\n",
       "      <td>paranoia someth struggl lot paranoia overthink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is happening to me?</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>1</td>\n",
       "      <td>happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I believe anxiety started this year and I real...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>1</td>\n",
       "      <td>believ anxieti start year realli dont anyon ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does one start therapy?</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>1</td>\n",
       "      <td>one start therapi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I heard a a lot of people experience less anxi...</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>1</td>\n",
       "      <td>heard lot peopl experi less anxieti stress sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426491</th>\n",
       "      <td>What is your own definition of happiness, or w...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>definit happi give happi life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426492</th>\n",
       "      <td>how much do you earn per month? state your age...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>much earn per month state age nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426493</th>\n",
       "      <td>I went to a theme park and rode multiple rolle...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>went theme park rode multipl rollercoast went ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426494</th>\n",
       "      <td>People do Reddit, what’s the most questionable...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>peopl reddit what question thing that happen o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426495</th>\n",
       "      <td>What movie that made others cry didn’t make yo...</td>\n",
       "      <td>ask_reddit</td>\n",
       "      <td>0</td>\n",
       "      <td>movi made other cri didnt make reaction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426496 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text      source  label  \\\n",
       "0       Paranoia is something I struggle with a lot, p...     anxiety      1   \n",
       "1                                What is happening to me?     anxiety      1   \n",
       "2       I believe anxiety started this year and I real...     anxiety      1   \n",
       "3                             How does one start therapy?     anxiety      1   \n",
       "4       I heard a a lot of people experience less anxi...     anxiety      1   \n",
       "...                                                   ...         ...    ...   \n",
       "426491  What is your own definition of happiness, or w...  ask_reddit      0   \n",
       "426492  how much do you earn per month? state your age...  ask_reddit      0   \n",
       "426493  I went to a theme park and rode multiple rolle...  ask_reddit      0   \n",
       "426494  People do Reddit, what’s the most questionable...  ask_reddit      0   \n",
       "426495  What movie that made others cry didn’t make yo...  ask_reddit      0   \n",
       "\n",
       "                                               clean_text  \n",
       "0       paranoia someth struggl lot paranoia overthink...  \n",
       "1                                                  happen  \n",
       "2       believ anxieti start year realli dont anyon ta...  \n",
       "3                                       one start therapi  \n",
       "4       heard lot peopl experi less anxieti stress sto...  \n",
       "...                                                   ...  \n",
       "426491                      definit happi give happi life  \n",
       "426492               much earn per month state age nation  \n",
       "426493  went theme park rode multipl rollercoast went ...  \n",
       "426494  peopl reddit what question thing that happen o...  \n",
       "426495            movi made other cri didnt make reaction  \n",
       "\n",
       "[426496 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'] = df.text.apply(preprocess_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top n-gram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['split'] = np.random.choice([\"train\", \"val\", \"test\"], size=df.shape[0], p=[.7, .15, .15])\n",
    "x_train = df[df[\"split\"] == \"train\"]\n",
    "y_train = x_train[\"label\"]\n",
    "x_val = df[df[\"split\"] == \"val\"]\n",
    "y_val = x_val[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                ('classifier', LinearSVC(class_weight='balanced'))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Training pipeline\n",
    "tf_idf = Pipeline([\n",
    "     ('tfidf', TfidfVectorizer(ngram_range=(1,3))),\n",
    "     (\"classifier\", svm.LinearSVC(C=1.0, class_weight=\"balanced\"))\n",
    " ])\n",
    "\n",
    "tf_idf.fit(x_train[\"clean_text\"], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9320573564135041"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Confidence measure\n",
    "f1_score(y_val, tf_idf.predict(x_val[\"clean_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = tf_idf.named_steps[\"classifier\"].coef_\n",
    "if type(coefs) == csr_matrix:\n",
    "    coefs.toarray().tolist()[0]\n",
    "else:\n",
    "    coefs.tolist()\n",
    "    \n",
    "feature_names = tf_idf.named_steps[\"tfidf\"].get_feature_names()\n",
    "coefs_and_features = list(zip(coefs[0], feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anxity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(14.301703991879622, anxieti)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(9.585010495490478, anxious)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(7.674457306810314, im)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(5.785025610697328, panic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(5.763425014243243, ive)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          anxity\n",
       "0  (14.301703991879622, anxieti)\n",
       "1   (9.585010495490478, anxious)\n",
       "2        (7.674457306810314, im)\n",
       "3     (5.785025610697328, panic)\n",
       "4       (5.763425014243243, ive)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_grams = pd.DataFrame()\n",
    "top_grams[\"anxity\"] = sorted(coefs_and_features, key=lambda x: x[0], reverse=True)[:50]\n",
    "top_grams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.9 s ± 522 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "# ## Build features for clean_text\n",
    "# features = [x[1] for x in sorted(coefs_and_features, key=lambda x: x[0], reverse=True)[:100]]\n",
    "# for feature in features:\n",
    "#     df[feature] = df.clean_text.str.contains(feature).map(int)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Build features for clean_text\n",
    "feature_arrays = []\n",
    "features = [x[1] for x in sorted(coefs_and_features, key=lambda x: x[0], reverse=True)[:5000]]\n",
    "\n",
    "for feature in features:\n",
    "    feature_arrays.append(df.clean_text.str.contains(feature).map(int).values)\n",
    "feature_df = pd.DataFrame(np.stack(feature_arrays, axis=1), columns=features)\n",
    "pd.concat((df, feature_df), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Build train & test set \n",
    "X = df.drop(columns=['text', 'source', 'label', 'clean_text', 'split'])\n",
    "Y = df.label\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X, Y, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## 5-fold cross validation\n",
    "clf = svm.LinearSVC()\n",
    "\n",
    "cv_metrics = [cross_val_score(clf, X, Y, cv=5, scoring='precision').mean(),\n",
    "              cross_val_score(clf, X, Y, cv=5, scoring='recall').mean(),\n",
    "              cross_val_score(clf, X, Y, cv=5, scoring='accuracy').mean(),\n",
    "              cross_val_score(clf, X, Y, cv=5, scoring='f1').mean()]\n",
    "metric[positive_file_names[0] + \"_CV\"] = cv_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"SVM claasifier F1 score: {0}\".format(f1_score(Y_test, clf.predict(X_test))))\n",
    "\n",
    "test_metrics = [precision_score(Y_test, clf.predict(X_test)),\n",
    "                recall_score(Y_test, clf.predict(X_test)),\n",
    "                accuracy_score(Y_test, clf.predict(X_test)),\n",
    "                f1_score(Y_test, clf.predict(X_test))]\n",
    "metric[positive_file_names[0] + \"_test\"] = cv_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the model\n",
    "with open(positive_file_names[0] + '.sav', 'wb') as sav:\n",
    "    pickle.dump(clf, sav)\n",
    "# loaded_model = pickle.load(open(positive_file_names[0] + '.sav', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2bc74cc49154a9ee15c00e6801fd896878f8e345944270608f40bd45df5df7c1"
  },
  "kernelspec": {
   "display_name": "causal_inference",
   "language": "python",
   "name": "causal_inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
